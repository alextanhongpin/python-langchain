{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73572eb9-76c0-42b0-81c5-31330c23351a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Large Language Models (LLMs) with Langchain\n",
    "\n",
    "Things that we can do with Langchain:\n",
    "\n",
    "- LLMs: Get predictions from language model\n",
    "- Prompt Templates: manage prompts for LLMs\n",
    "- Chains: combine LLMs and prompts in multi-step workflows\n",
    "- Agents: dynamically call chains based on user input\n",
    "- Memory: add state to Chain and Agents\n",
    "\n",
    "\n",
    "> To better understand the modules/variables, suffix the variables with a question mark, e.g. OpenAI? or press CMD + I and click on the variables to display contextual help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4154a8-5f79-4cfb-9282-746139b9075a",
   "metadata": {},
   "source": [
    "## LLMs: Get predictions from a language model\n",
    "\n",
    "Let's build a service that generates a company name based on what the company makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d88b41b8-7709-474d-8c5a-ea4200156a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stable Diffusion Solutions\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "text = \"What would be a good company name for a startup that specializes in stable diffusion?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42401ae0-1e79-48aa-9906-ecb9d28f5730",
   "metadata": {},
   "source": [
    "## Prompt Templates: manage prompts for LLMs\n",
    "\n",
    "When using LLMs, we usually work with a specific prompt. Instead of constructing it everytime, we can use prompt template with variables substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c88f503d-7673-47f5-bb29-7b642f50654e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be a good company name for a startup that specializes in deep learning?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"tech\"],\n",
    "    template=\"What would be a good company name for a startup that specializes in {tech}?\",\n",
    ")\n",
    "print(prompt.format(tech=\"deep learning\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3dba8e-39d1-4ce7-aeb2-eda476d5a7ba",
   "metadata": {},
   "source": [
    "## Chains: combine LLMs and prompts in multi-step workflows\n",
    "\n",
    "PromptTemplate and LLMs are primitives by themselves. Applications usually are a combination of primitives.\n",
    "\n",
    "A chain in LangChain is made up of links, which can be either primitives like LLMs or other chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee50bff0-80ba-46bb-b678-02c576e69a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DeepLearnTech Solutions\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"tech\"],\n",
    "    template=\"What would be a good company name for a startup that specializes in {tech}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"deep learning\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d685ee-a767-430a-9ebc-b5f76228758e",
   "metadata": {},
   "source": [
    "## Agents: Dynamically Call Chains based on user input\n",
    "\n",
    "Unlike chains, agents do not run in a predetermined order.\n",
    "\n",
    "Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "Some important concepts when loading agents:\n",
    "\n",
    "- **Tool**: a function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool currently is `fn(str): -> str`, a function that is expected to have a string as an input, with a string as an output\n",
    "- **LLM**: The language model powering an agent\n",
    "- **Agent**: The agent to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316b5ac6-dd4a-4c65-8d9d-6d5aebb51886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -qq only prints out error\n",
    "!pip install -qq google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb010c91-8225-4e98-90a8-4921dc4f2d42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the temperature in Singapore and then calculate the power of 0.5\n",
      "Action: Search\n",
      "Action Input: \"High temperature in Singapore yesterday\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHigh & Low Weather Summary for the Past Weeks ; 82 °F · 78% ; * Reported Mar 26 5:00 pm — Apr 10 5:35 pm, Singapore.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to convert the temperature from Fahrenheit to Celcius\n",
      "Action: Calculator\n",
      "Action Input: 82°F to Celcius\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 27.77777777777778\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the power of 0.5\n",
      "Action: Calculator\n",
      "Action Input: 27.77777777777778^0.5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.270462766947299\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The high temperature in Singapore yesterday in Celcius was 27.77777777777778 and the number raised to the power of 0.5 is 5.270462766947299.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The high temperature in Singapore yesterday in Celcius was 27.77777777777778 and the number raised to the power of 0.5 is 5.270462766947299.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# First, let's load the language model we are going to use to control the agent.\n",
    "# We set the temperature, because we do not want our agent to be too creative.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Next, we load some tools to use.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "agent.run(\n",
    "    \"What was the high temperature in Singapore yesterday in Celcius? What is the number raised to the power of 0.5?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574eddc3-b400-412f-a427-36fa506125b8",
   "metadata": {},
   "source": [
    "## Memory: Add state to Chains and Agents\n",
    "\n",
    "Chains and Agents can be stateless or stateful. Stateful Chain or Agent have some concepts of \"memory\", so that it may remember information about its previous interaction.\n",
    "\n",
    "Some relevant application is a chatbot - you want it to remember the previous message so that it can use the context from that to have a better conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bff6b49-c67f-4b10-985b-f23bcef2533d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi there! How can I help you?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import ConversationChain, OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "conversation.predict(input=\"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9fe7260-66b7-4c83-aa70-fccbf8e2a680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: Just wanna ask your thoughts on AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" AI is an incredibly powerful technology that has the potential to revolutionize many aspects of our lives. It can be used to automate mundane tasks, improve decision-making, and even create new products and services. AI can also be used to improve healthcare, education, and transportation. I'm excited to see what the future holds for AI!\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Just wanna ask your thoughts on AI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
